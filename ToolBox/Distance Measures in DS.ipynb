{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Measures in Data Science "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= \\sqrt{\\sum \\limits_{i=1} ^n (x_{i}-y_{i})²}$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use Cases : Ok for low dimensional data where magnitude of vectors is important.\n",
    "Disadvantages : Need to normalize data before using this distance measure.\n",
    "Not usefull when the dimensionality go up (curse of dimensionality) ==> 2/3 dimension max (signal to noise : due to squared terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/56115205/euclidean-distance-between-two-pandas-dataframes\n",
    "\n",
    "def Euclidean_Dist(df1, df2, cols=['x_coord','y_coord']):\n",
    "    return np.linalg.norm(df1[cols].values - df2[cols].values,\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= \\cos{\\theta} = \\frac{{x}\\cdot{y}}{\\|x\\|\\cdot\\|y\\|}$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "use cases : deal with high dimensional data and when magnitude is not of importance. \n",
    "Useful for text analyses : word count\n",
    "    ==> en comparant 2 documents, si dans l'un le mot apparait plus souvent, ca ne veut pas forcément dire que ce dernier est traite plus du sujet. Ca peut être pcq le document est très long ==> On ne peut pas regarder la magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "distance.cosine([1,0,0],[0,1,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of element which are different between two vectors.\n",
    "Use Case : distance between categorical variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distance sur un échequier , pas la plus courte (euclidienne).\n",
    "La distance est donc plus grande que l'euclidienne. Pas forcément dérangeant mais à garder en tête. \n",
    "Cette distance n'est pas sujet à problème avec l'augmentation du nombre de dimension.\n",
    "De manière général, le concept est moins intuitif\n",
    "\n",
    "A utiliser lorsque le jdd est constitué de valeur discrète/binaire. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= \\sum \\limits _{i=1} ^{n} {|x_{i}-y_{i}|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "a = np.array([[ 0.1,  0.2,  0.4]])\n",
    "b = np.array([[ 0.3,  0.2,  0.4]])\n",
    "out = cdist(a, b, metric='cityblock')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chebyshev Distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plus grande distance entre les éléments des deux vecteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= \\max_{i} ({|x_{i}-y_{i}|})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "out = cdist(a, b, metric='chebyshev')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ne s'utilise que lorsqu'il faut extraire le nombre minimum de mouvement nécessaire pour aller d'une case à l'autre.  Utilisé en pratique dans les centres logistiques, pour le mouvenent des engins de manutention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minkowsky Distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "génération des distances euclidiennes, manhathan etcs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= (\\sum \\limits _{i=1} ^{n} {|x_{i}-y_{i}|}^{p})^{\\frac{1}{p}} $$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Peut être calculatoirement plus couteux, du fait de la puissance. Même désavantage que les Euclidiens, Manhattan, Chebyshev etcs.\n",
    "L'avantage consiste à pouvoir itérer sur p pour trouver la distance qui convient le mieux==> Très flexible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2]]\n"
     ]
    }
   ],
   "source": [
    "out = cdist(a, b, 'minkowski', p=0.5)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pour calculer la similarité et diversité dans un ensemble de test. \n",
    "==> nbr total de similarité divisé par le nbr total d'entité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= 1- {\\frac{|{x}\\cap{y}|}{|{y}\\cup{x}|}} $$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s'utilise sur les cas binaires.  Par exemple, la prédiction de segment sur une image, ou bien sur la similarité d'un texte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdist(a, b, 'jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haversine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distance entre deux points sur une sphère, à partir de la latitude et longitude. S'utilise en navigatio, pour la distance entre deux pays.  Vraiement utile si il faut tenir compte de la courbure. Vu de près, la terre est plate\n",
    "Vu que la terre est plutot elipsoid, la distance de Vincenty est à envisager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorensen-Dice Index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Elle ressemble à l'index de Jacard. Même cas d'usage, autres distances à envisager  (Mahalanobis, Canberra, Braycurtis, and KL-divergence.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$ D(x,y)= {\\frac{2 |{x}\\cap{y}|}{|{y}|+|{x}|}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice similarity score is 0.75\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/31273652/how-to-calculate-dice-coefficient-for-measuring-accuracy-of-image-segmentation-i\n",
    "import numpy as np\n",
    "\n",
    "k=1\n",
    "\n",
    "# segmentation\n",
    "seg = np.zeros((100,100), dtype='int')\n",
    "seg[30:70, 30:70] = k\n",
    "\n",
    "# ground truth\n",
    "gt = np.zeros((100,100), dtype='int')\n",
    "gt[30:70, 40:80] = k\n",
    "\n",
    "dice = np.sum(seg[gt==k])*2.0 / (np.sum(seg) + np.sum(gt))\n",
    "\n",
    "print( 'Dice similarity score is {}'.format(dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
